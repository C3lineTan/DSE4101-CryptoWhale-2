{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating baseline model EGARCH for ETH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from arch.univariate import EGARCH, ZeroMean, StudentsT, Normal\n",
    "from statsmodels.tools.sm_exceptions import InterpolationWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to import this for rmse and qlike\n",
    "#import numpy as np\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "\n",
    "\n",
    "def qlike(y2, var_fc, eps=1e-12):\n",
    "    ratio = (y2 + eps) / (var_fc + eps)\n",
    "    return float(np.mean(ratio - np.log(ratio) - 1.0))\n",
    "\n",
    "\n",
    "def clean_series(x, name=\"series\"):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").astype(float)\n",
    "    x = x.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if not x.index.is_monotonic_increasing:\n",
    "        x = x.sort_index()\n",
    "    return x\n",
    "\n",
    "\n",
    "def scale_series(x, factor=100.0):\n",
    "    if factor is None or factor == 1.0:\n",
    "        return x, 1.0\n",
    "    return x * factor, factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index dtype: datetime64[ns, UTC]\n",
      "Columns: Index(['RV_MA_1hr', 'RV_MA_3hr', 'RV_MA_12hr', 'vol_future',\n",
      "       'active_sending_addresses', 'active_receiving_addresses',\n",
      "       'exchange_withdrawing_count', 'transaction_count', 'fail_rate_percent',\n",
      "       'open', 'low', 'high', 'close', 'hourly_return',\n",
      "       'onchain_volume_usd_log', 'avg_gas_fee_usd_log',\n",
      "       'avg_priority_fee_usd_log', 'staking_inflow_log',\n",
      "       'exchange_depositing_count_log', 'exchange_netflow_usd_log',\n",
      "       'whale_net_usd', 'whale_net_usd_24h', 'whale_burst_flag',\n",
      "       'etow_usd_log', 'etow_coins_log', 'whale_txn_count_log', 'wtoe_usd_log',\n",
      "       'wtoe_coins_log', 'btc_to_eth_spill'],\n",
      "      dtype='object')\n",
      "Data shape: (8208, 29)\n",
      "\n",
      "Using 8208 observations for EGARCH modelling.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/eth_final_df.csv\")\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "df = df.set_index('timestamp')\n",
    "df = df.sort_index()\n",
    "df = df[~df.index.duplicated(keep='last')]\n",
    "df = df.asfreq('h')  # make sure it's hourly\n",
    "\n",
    "\n",
    "r = df['hourly_return']\n",
    "\n",
    "print(\"Index dtype:\", df.index.dtype)\n",
    "print(\"Columns:\", df.columns)\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(f\"\\nUsing {len(r)} observations for EGARCH modelling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining stationary tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stationarity Tests ===\n",
      "{'ADF': {'stat': np.float64(-18.646556209260286), 'p': np.float64(2.052218387867681e-30)}, 'KPSS_level': {'stat': np.float64(0.1810942409319947), 'p': np.float64(0.1)}, 'KPSS_trend': {'stat': np.float64(0.14541966082436722), 'p': np.float64(0.051074702177097725)}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/bmfws9h55z1g8ckt55h4p8jr0000gn/T/ipykernel_6866/463190570.py:4: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  kpss_level = kpss(x, regression=\"c\", nlags=\"auto\")\n"
     ]
    }
   ],
   "source": [
    "def adf_kpss(x: pd.Series):\n",
    "    x = x.dropna()\n",
    "    adf_res = adfuller(x, autolag=\"AIC\")\n",
    "    kpss_level = kpss(x, regression=\"c\", nlags=\"auto\")\n",
    "    kpss_trend = kpss(x, regression=\"ct\", nlags=\"auto\")\n",
    "    return {\n",
    "        \"ADF\": {\"stat\": adf_res[0], \"p\": adf_res[1]},\n",
    "        \"KPSS_level\": {\"stat\": kpss_level[0], \"p\": kpss_level[1]},\n",
    "        \"KPSS_trend\": {\"stat\": kpss_trend[0], \"p\": kpss_trend[1]},\n",
    "    }\n",
    "\n",
    "print(\"\\n=== Stationarity Tests ===\")\n",
    "print(adf_kpss(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use table to show at least weak stationarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Statistic</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "      <th>Decision @ 5%</th>\n",
       "      <th>Lags used</th>\n",
       "      <th>Obs used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADF</td>\n",
       "      <td>-18.646556</td>\n",
       "      <td>2.052218e-30</td>\n",
       "      <td>Unit root (non-stationary)</td>\n",
       "      <td>Stationary (reject H0)</td>\n",
       "      <td>25</td>\n",
       "      <td>8182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KPSS (level)</td>\n",
       "      <td>0.181094</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>Level-stationary</td>\n",
       "      <td>Stationary (fail to reject)</td>\n",
       "      <td>14</td>\n",
       "      <td>8208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KPSS (trend)</td>\n",
       "      <td>0.145420</td>\n",
       "      <td>5.107470e-02</td>\n",
       "      <td>Trend-stationary</td>\n",
       "      <td>Stationary (fail to reject)</td>\n",
       "      <td>14</td>\n",
       "      <td>8208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Test  Statistic       p-value                          H0  \\\n",
       "0           ADF -18.646556  2.052218e-30  Unit root (non-stationary)   \n",
       "1  KPSS (level)   0.181094  1.000000e-01            Level-stationary   \n",
       "2  KPSS (trend)   0.145420  5.107470e-02            Trend-stationary   \n",
       "\n",
       "                 Decision @ 5%  Lags used  Obs used  \n",
       "0       Stationary (reject H0)         25      8182  \n",
       "1  Stationary (fail to reject)         14      8208  \n",
       "2  Stationary (fail to reject)         14      8208  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stationarity_table(x, alpha=0.05):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").astype(float).dropna()\n",
    "\n",
    "    adf_stat, adf_p, adf_lags, adf_nobs, adf_crit, *_ = adfuller(x, autolag=\"AIC\")\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=InterpolationWarning)\n",
    "        kpss_level_stat, kpss_level_p, kpss_level_lags, kpss_level_crit = kpss(x, regression=\"c\", nlags=\"auto\")\n",
    "        kpss_trend_stat, kpss_trend_p, kpss_trend_lags, kpss_trend_crit = kpss(x, regression=\"ct\", nlags=\"auto\")\n",
    "\n",
    "    rows = [\n",
    "        {\n",
    "            \"Test\": \"ADF\",\n",
    "            \"Statistic\": adf_stat,\n",
    "            \"p-value\": adf_p,\n",
    "            \"H0\": \"Unit root (non-stationary)\",\n",
    "            f\"Decision @ {int(alpha*100)}%\": \"Stationary (reject H0)\" if adf_p < alpha else \"Non-stationary (fail to reject)\",\n",
    "            \"Lags used\": adf_lags,\n",
    "            \"Obs used\": adf_nobs,\n",
    "        },\n",
    "        {\n",
    "            \"Test\": \"KPSS (level)\",\n",
    "            \"Statistic\": kpss_level_stat,\n",
    "            \"p-value\": kpss_level_p,\n",
    "            \"H0\": \"Level-stationary\",\n",
    "            f\"Decision @ {int(alpha*100)}%\": \"Non-stationary (reject H0)\" if kpss_level_p < alpha else \"Stationary (fail to reject)\",\n",
    "            \"Lags used\": kpss_level_lags,\n",
    "            \"Obs used\": len(x),\n",
    "        },\n",
    "        {\n",
    "            \"Test\": \"KPSS (trend)\",\n",
    "            \"Statistic\": kpss_trend_stat,\n",
    "            \"p-value\": kpss_trend_p,\n",
    "            \"H0\": \"Trend-stationary\",\n",
    "            f\"Decision @ {int(alpha*100)}%\": \"Non-stationary (reject H0)\" if kpss_trend_p < alpha else \"Stationary (fail to reject)\",\n",
    "            \"Lags used\": kpss_trend_lags,\n",
    "            \"Obs used\": len(x),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    return df_out\n",
    "\n",
    "    num_cols = [\"Statistic\", \"p-value\"]\n",
    "    df_out[num_cols] = df_out[num_cols].applymap(lambda v: np.nan if pd.isna(v) else float(v))\n",
    "    return df_out\n",
    "\n",
    "tbl = stationarity_table(r, alpha=0.05)\n",
    "tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train+Validation/Test Split (85/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val for CV: 7000 obs  |  Test (after 24h purge): 1208 obs\n",
      "Rolling CV plan → train=6376, test=120, purge=24, folds=5 (train_val length=7000)\n"
     ]
    }
   ],
   "source": [
    "use_validation = True \n",
    "n = len(r)\n",
    "if use_validation:\n",
    "    n_train = int(0.70 * n)\n",
    "    n_val   = int(0.15 * n)\n",
    "    train_proto = r.iloc[:n_train]\n",
    "    val_proto   = r.iloc[n_train:n_train+n_val]\n",
    "    test_proto  = r.iloc[n_train+n_val:]\n",
    "else:\n",
    "    n_train = int(0.85 * n)\n",
    "    train_proto = r.iloc[:n_train]\n",
    "    val_proto   = None\n",
    "    test_proto  = r.iloc[n_train:]\n",
    "\n",
    "PURGE_HOURS = 24\n",
    "N_SPLITS = 5 \n",
    "if len(test_proto) == 0:\n",
    "    raise ValueError(\"Empty test set after temporal split.\")\n",
    "boundary = test_proto.index.min()\n",
    "purged_start = boundary + pd.Timedelta(hours=PURGE_HOURS)\n",
    "\n",
    "train_val = r.loc[: purged_start - pd.Timedelta(hours=1)]\n",
    "test      = r.loc[purged_start:]\n",
    "\n",
    "print(f\"Train/Val for CV: {len(train_val)} obs  |  Test (after 24h purge): {len(test)} obs\")\n",
    "\n",
    "#picking fixed sizes to fit in train_val\n",
    "N_SPLITS    = 5\n",
    "TEST_SIZE   = 24 * 5      \n",
    "n           = len(train_val)\n",
    "\n",
    "# Pick TRAIN_SIZE to fit the feasibility condition:\n",
    "TRAIN_SIZE = n - (PURGE_HOURS + N_SPLITS * TEST_SIZE)\n",
    "\n",
    "print(f\"Rolling CV plan → train={TRAIN_SIZE}, test={TEST_SIZE}, purge={PURGE_HOURS}, folds={N_SPLITS} \"\n",
    "      f\"(train_val length={n})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling Window = 5 Splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_split_fixed(x, *, train_size, test_size, purge=24, n_splits=None):\n",
    "    n = len(x)\n",
    "    step = test_size\n",
    "    start_train = 0\n",
    "    k = 0\n",
    "\n",
    "    while True:\n",
    "        end_train   = start_train + train_size               \n",
    "        start_test  = end_train + purge\n",
    "        end_test    = start_test + test_size                  \n",
    "\n",
    "        if end_test > n:                                     \n",
    "            break\n",
    "        yield (np.arange(start_train, end_train),\n",
    "               np.arange(start_test,  end_test))\n",
    "\n",
    "        k += 1\n",
    "        if (n_splits is not None) and (k >= n_splits):\n",
    "            break\n",
    "        \n",
    "        start_train += step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit EGARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def egarch_path_refit(train_ret, test_ret, dist=\"t\", scale=100.0):\n",
    "    tr = clean_series(train_ret, \"train_ret\")\n",
    "    te = clean_series(test_ret, \"test_ret\")\n",
    "\n",
    "    tr_s, s = scale_series(tr, scale)\n",
    "    te_s, _ = scale_series(te, scale)\n",
    "\n",
    "    all_s = pd.concat([tr_s, te_s])\n",
    "    n_tr, n_te = len(tr_s), len(te_s)\n",
    "\n",
    "    var_fc_s = np.empty(n_te)\n",
    "\n",
    "    for j in range(n_te):\n",
    "        y_fit = all_s.iloc[: n_tr + j]\n",
    "        model = ZeroMean(y_fit)\n",
    "        model.volatility = EGARCH(p=1, o=1, q=1)\n",
    "        model.distribution = StudentsT() if dist == \"t\" else Normal()\n",
    "        res = model.fit(disp=\"off\")\n",
    "\n",
    "        fcast = res.forecast(horizon=1, reindex=False)\n",
    "        var_fc_s[j] = float(fcast.variance.values[-1, 0])\n",
    "\n",
    "    var_fc = var_fc_s / (s ** 2)\n",
    "    r2 = te.values ** 2\n",
    "\n",
    "    return {\n",
    "        \"var_fc\": var_fc,\n",
    "        \"r2\": r2,\n",
    "        \"rmse\": rmse(r2, var_fc),\n",
    "        \"qlike\": qlike(r2, var_fc),\n",
    "        \"n_train\": len(tr),\n",
    "        \"n_test\": len(te),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add RMSE Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best EGARCH tuning by RMSE\n",
      "  Distribution: t\n",
      "  Scale:        100.0\n",
      "  RMSE:         0.000133\n"
     ]
    }
   ],
   "source": [
    "candidates = [\n",
    "    (\"t\", 100.0),\n",
    "    (\"normal\", 100.0),\n",
    "    (\"t\", 1000.0),\n",
    "    (\"normal\", 1000.0),\n",
    "]\n",
    "\n",
    "tune_results = []\n",
    "for dist, scale in candidates:\n",
    "    o = egarch_path_refit(train_val, test, dist=dist, scale=scale)\n",
    "    tune_results.append((dist, scale, o[\"rmse\"]))\n",
    "\n",
    "#rank by lowest RMSE \n",
    "tune_results = sorted(tune_results, key=lambda x: x[2])\n",
    "best_dist, best_scale, best_rmse = tune_results[0]\n",
    "\n",
    "print(\"Best EGARCH tuning by RMSE\")\n",
    "print(f\"  Distribution: {best_dist}\")\n",
    "print(f\"  Scale:        {best_scale}\")\n",
    "print(f\"  RMSE:         {best_rmse:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation (5 splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rolling CV ===\n",
      "Fold 1: RMSE=7.989145e-05 | QLIKE=1.420418 | Train=6376 Test=120\n",
      "Fold 2: RMSE=9.802757e-05 | QLIKE=1.738594 | Train=6376 Test=120\n",
      "Fold 3: RMSE=1.153271e-04 | QLIKE=1.812964 | Train=6376 Test=120\n",
      "Fold 4: RMSE=8.584808e-05 | QLIKE=1.270342 | Train=6376 Test=120\n",
      "Fold 5: RMSE=4.865892e-04 | QLIKE=2.177654 | Train=6376 Test=120\n",
      "\n",
      "Mean CV RMSE=1.731367e-04 | Mean CV QLIKE=1.683994\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Rolling CV ===\")\n",
    "cv_scores = []\n",
    "\n",
    "for i, (tri, tei) in enumerate(\n",
    "        rolling_split_fixed(train_val,\n",
    "                            train_size=TRAIN_SIZE,\n",
    "                            test_size=TEST_SIZE,\n",
    "                            purge=PURGE_HOURS,\n",
    "                            n_splits=N_SPLITS), 1):\n",
    "    tr_i = train_val.iloc[tri]\n",
    "    te_i = train_val.iloc[tei]\n",
    "\n",
    "    out = egarch_path_refit(\n",
    "        tr_i, te_i,\n",
    "        dist=best_dist if 'best_dist' in globals() else \"t\",\n",
    "        scale=best_scale if 'best_scale' in globals() else 100.0\n",
    "    )\n",
    "    cv_scores.append((out[\"rmse\"], out[\"qlike\"]))\n",
    "    print(f\"Fold {i}: RMSE={out['rmse']:.6e} | QLIKE={out['qlike']:.6f} \"\n",
    "          f\"| Train={out['n_train']} Test={out['n_test']}\")\n",
    "\n",
    "if cv_scores:\n",
    "    mean_rmse  = float(np.mean([s[0] for s in cv_scores]))\n",
    "    mean_qlike = float(np.mean([s[1] for s in cv_scores]))\n",
    "    print(f\"\\nMean CV RMSE={mean_rmse:.6e} | Mean CV QLIKE={mean_qlike:.6f}\")\n",
    "else:\n",
    "    print(\"No valid CV folds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Test Results ===\n",
      "Test RMSE=1.325891e-04 | QLIKE=1.913727\n"
     ]
    }
   ],
   "source": [
    "final_train = train_val \n",
    "final_out = egarch_path_refit(final_train, test, dist=\"t\", scale=100.0)\n",
    "print(\"\\n=== Final Test Results ===\")\n",
    "print(f\"Test RMSE={final_out['rmse']:.6e} | QLIKE={final_out['qlike']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on why RMSE is so low - due to scaling since returns are of small magnitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale checks:\n",
      "mean|r|     = 4.963e-03\n",
      "mean r^2    = 5.731e-05\n",
      "std(r)^2    = 5.731e-05\n",
      "\n",
      "Metrics (scientific):\n",
      "RMSE       = 1.326e-04\n",
      "QLIKE      = 1.913727\n",
      "\n",
      "Forecast variance summary:\n",
      "min=9.852e-06  p50=3.511e-05  mean=4.586e-05  max=4.232e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"Scale checks:\")\n",
    "print(f\"mean|r|     = {np.mean(np.abs(r)):.3e}\")\n",
    "print(f\"mean r^2    = {np.mean(r**2):.3e}\")\n",
    "print(f\"std(r)^2    = {np.std(r)**2:.3e}\")  \n",
    "\n",
    "\n",
    "print(\"\\nMetrics (scientific):\")\n",
    "print(f\"RMSE       = {final_out['rmse']:.3e}\")   \n",
    "print(f\"QLIKE      = {final_out['qlike']:.6f}\")\n",
    "\n",
    "\n",
    "vf = final_out['var_fc']\n",
    "print(\"\\nForecast variance summary:\")\n",
    "print(f\"min={vf.min():.3e}  p50={np.median(vf):.3e}  mean={vf.mean():.3e}  max={vf.max():.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save CSV for ETH EGARCH Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EGARCH Volatility Forecast Results ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_vol_future</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-08-23 16:00:00+00:00</th>\n",
       "      <td>0.006138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-23 17:00:00+00:00</th>\n",
       "      <td>0.006046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-23 18:00:00+00:00</th>\n",
       "      <td>0.005640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-23 19:00:00+00:00</th>\n",
       "      <td>0.005354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-23 20:00:00+00:00</th>\n",
       "      <td>0.005124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-23 21:00:00+00:00</th>\n",
       "      <td>0.004994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-23 22:00:00+00:00</th>\n",
       "      <td>0.004719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-23 23:00:00+00:00</th>\n",
       "      <td>0.004878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 00:00:00+00:00</th>\n",
       "      <td>0.004710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 01:00:00+00:00</th>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 02:00:00+00:00</th>\n",
       "      <td>0.005119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 03:00:00+00:00</th>\n",
       "      <td>0.004925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 04:00:00+00:00</th>\n",
       "      <td>0.004911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 05:00:00+00:00</th>\n",
       "      <td>0.004746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 06:00:00+00:00</th>\n",
       "      <td>0.004544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 07:00:00+00:00</th>\n",
       "      <td>0.004908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 08:00:00+00:00</th>\n",
       "      <td>0.004613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 09:00:00+00:00</th>\n",
       "      <td>0.004516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 10:00:00+00:00</th>\n",
       "      <td>0.004340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-24 11:00:00+00:00</th>\n",
       "      <td>0.005282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           pred_vol_future\n",
       "timestamp                                 \n",
       "2025-08-23 16:00:00+00:00         0.006138\n",
       "2025-08-23 17:00:00+00:00         0.006046\n",
       "2025-08-23 18:00:00+00:00         0.005640\n",
       "2025-08-23 19:00:00+00:00         0.005354\n",
       "2025-08-23 20:00:00+00:00         0.005124\n",
       "2025-08-23 21:00:00+00:00         0.004994\n",
       "2025-08-23 22:00:00+00:00         0.004719\n",
       "2025-08-23 23:00:00+00:00         0.004878\n",
       "2025-08-24 00:00:00+00:00         0.004710\n",
       "2025-08-24 01:00:00+00:00         0.005031\n",
       "2025-08-24 02:00:00+00:00         0.005119\n",
       "2025-08-24 03:00:00+00:00         0.004925\n",
       "2025-08-24 04:00:00+00:00         0.004911\n",
       "2025-08-24 05:00:00+00:00         0.004746\n",
       "2025-08-24 06:00:00+00:00         0.004544\n",
       "2025-08-24 07:00:00+00:00         0.004908\n",
       "2025-08-24 08:00:00+00:00         0.004613\n",
       "2025-08-24 09:00:00+00:00         0.004516\n",
       "2025-08-24 10:00:00+00:00         0.004340\n",
       "2025-08-24 11:00:00+00:00         0.005282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved EGARCH results to: ../Results/eth_egarch_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "pred_vol_future = np.sqrt(np.maximum(final_out[\"var_fc\"], 0.0))\n",
    "vol_future_df = pd.DataFrame(\n",
    "    {\n",
    "        \"pred_vol_future\": pred_vol_future,\n",
    "    },\n",
    "    index=test.index,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"=== EGARCH Volatility Forecast Results ===\")\n",
    "display(vol_future_df.head(20))  \n",
    "\n",
    "\n",
    "output_path = \"../Results/eth_egarch_prediction.csv\"\n",
    "vol_future_df.to_csv(output_path, index_label=\"timestamp\")\n",
    "\n",
    "print(f\"\\nSaved EGARCH results to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EGARCH (Local)",
   "language": "python",
   "name": "egarch_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
