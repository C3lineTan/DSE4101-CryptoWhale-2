{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 8208\n"
     ]
    }
   ],
   "source": [
    "base_path = \"../Data/btc_final_df.csv\"\n",
    "lstm_path = \"../Results/btc_lstm_prediction.csv\"\n",
    "egarch_path = \"../Results/btc_egarch_prediction.csv\"\n",
    "xgb_path = \"../Results/btc_xgb_prediction.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(base_path, parse_dates=[\"timestamp\"])\n",
    "# keep only the columns you need\n",
    "need = [\"timestamp\", \"open\", \"low\", \"high\", \"close\", \"vol_future\"]\n",
    "df = df[need].copy()\n",
    "\n",
    "\n",
    "if df[\"timestamp\"].dt.tz is None:\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].dt.tz_localize(\"UTC\")\n",
    "df = df.drop_duplicates(subset=\"timestamp\").sort_values(\"timestamp\")\n",
    "\n",
    "\n",
    "def load_pred(path, new_col_name):\n",
    "    d = pd.read_csv(path, parse_dates=[\"timestamp\"])\n",
    "    # normalize timezone\n",
    "    if d[\"timestamp\"].dt.tz is None:\n",
    "        d[\"timestamp\"] = d[\"timestamp\"].dt.tz_localize(\"UTC\")\n",
    "    # allow for different original names like 'pred_vol_future' or 'vol_future_pred'\n",
    "    pred_col = None\n",
    "    for c in d.columns:\n",
    "        if c.lower() in {\"pred_vol_future\"}:\n",
    "            pred_col = c\n",
    "            break\n",
    "    if pred_col is None:\n",
    "        raise ValueError(f\"Could not find prediction column in {path}.\")\n",
    "    d = d[[\"timestamp\", pred_col]].rename(columns={pred_col: new_col_name})\n",
    "    return d.drop_duplicates(subset=\"timestamp\").sort_values(\"timestamp\")\n",
    "\n",
    "lstm = load_pred(lstm_path, \"lstm_pred_vol_future\")\n",
    "egarch = load_pred(egarch_path, \"egarch_pred_vol_future\")\n",
    "xgb = load_pred(xgb_path, \"xgb_pred_vol_future\")  # note: xgb (not xbg)\n",
    "\n",
    "# ---------- left-join predictions to the OHLC backbone ----------\n",
    "master = (df\n",
    "          .merge(lstm,  on=\"timestamp\", how=\"left\")\n",
    "          .merge(egarch, on=\"timestamp\", how=\"left\")\n",
    "          .merge(xgb,   on=\"timestamp\", how=\"left\"))\n",
    "\n",
    "print(\"Initial:\",len(master))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping NaNs: 1208 rows remain.\n",
      "                  timestamp       open        low       high      close  \\\n",
      "0 2025-08-23 16:00:00+00:00  114824.68  114699.35  114964.86  114964.86   \n",
      "1 2025-08-23 17:00:00+00:00  114987.13  114943.52  115089.33  115061.31   \n",
      "2 2025-08-23 18:00:00+00:00  115060.14  115035.54  115117.39  115112.79   \n",
      "\n",
      "   vol_future  lstm_pred_vol_future  egarch_pred_vol_future  \\\n",
      "0    0.001425              0.002926                0.002982   \n",
      "1    0.001241              0.002479                0.002805   \n",
      "2    0.001540              0.002281                0.002674   \n",
      "\n",
      "   xgb_pred_vol_future  \n",
      "0             0.004060  \n",
      "1             0.003855  \n",
      "2             0.003855  \n",
      "                     timestamp       open        low       high      close  \\\n",
      "1205 2025-10-12 21:00:00+00:00  115124.69  114573.45  115503.13  114757.84   \n",
      "1206 2025-10-12 22:00:00+00:00  114973.28  114973.28  115577.73  115540.33   \n",
      "1207 2025-10-12 23:00:00+00:00  115458.48  114932.12  115458.48  115208.85   \n",
      "\n",
      "      vol_future  lstm_pred_vol_future  egarch_pred_vol_future  \\\n",
      "1205    0.006577              0.005185                0.005864   \n",
      "1206    0.006362              0.006389                0.005800   \n",
      "1207    0.004646              0.006002                0.006134   \n",
      "\n",
      "      xgb_pred_vol_future  \n",
      "1205             0.005746  \n",
      "1206             0.006856  \n",
      "1207             0.007350  \n"
     ]
    }
   ],
   "source": [
    "# Drop all rows that have any missing prediction\n",
    "master = master.dropna(subset=[\n",
    "    \"lstm_pred_vol_future\",\n",
    "    \"egarch_pred_vol_future\",\n",
    "    \"xgb_pred_vol_future\"\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "print(\"After dropping NaNs:\", len(master), \"rows remain.\")\n",
    "print(master.head(3))\n",
    "print(master.tail(3))\n",
    "\n",
    "pred_cols = [c for c in [\"lstm_pred_vol_future\",\"egarch_pred_vol_future\",\n",
    "                         \"xgb_pred_vol_future\",\"tf_pred_vol_future\"] if c in master.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Backtesting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHAS     = (0.80, 0.85, 0.90, 0.95)    # looser threshold range → more trades, \n",
    "Q_WINDOW   = 24*7                        # 7-day rolling window (keep this)\n",
    "VAL_H      = 24*30                       # 30 days validation (more stable α selection)\n",
    "TEST_H     = 24*5                        # 5 days test (shorter, rolling forward faster)\n",
    "EMBARGO_H  = 1                           # keep small gap\n",
    "\n",
    "FEE_RATE   = 0.0005                      # 0.05% per side (test sensitivity to fees)\n",
    "SPEND_FRAC = 0.05                        # same (or lower to reduce overtrading)\n",
    "TP_PCT     = 0.02                        # widen target (+2%)\n",
    "TSL_PCT    = 0.01                        # wider trailing stop (–1%)\n",
    "INIT_CASH  = 10000.0\n",
    "H_PER_YR   = 24*365\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features (returns) & utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "master[\"ret_log\"] = np.log(master[\"close\"]).diff()\n",
    "master[\"ret_2h\"]  = master[\"ret_log\"].rolling(2).sum()\n",
    "\n",
    "def rolling_quantile(series, window, alpha):\n",
    "    # use ONLY past data: shift by 1 hour to avoid look-ahead\n",
    "    return series.shift(1).rolling(window=window, min_periods=max(6, window//2)).quantile(alpha)\n",
    "\n",
    "def build_enter_flags(df, pred_col, alpha, q_window, mode):\n",
    "    q = rolling_quantile(df[\"vol_future\"], q_window, alpha)\n",
    "    spike = (df[pred_col] > q)\n",
    "    if mode == \"momentum\":\n",
    "        cond = df[\"ret_2h\"] > 0\n",
    "    elif mode == \"meanrev\":\n",
    "        cond = df[\"ret_2h\"] < 0\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'momentum' or 'meanrev'\")\n",
    "\n",
    "    sig = (spike & cond).astype(bool)\n",
    "    # decide at hour h close; EXECUTE next hour open\n",
    "    return sig.shift(1, fill_value=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broker backtest engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_block(df_blk, enter_flags,\n",
    "                   fee_rate=FEE_RATE, spend_frac=SPEND_FRAC,\n",
    "                   tp=TP_PCT, tsl=TSL_PCT, initial_cash=INIT_CASH):\n",
    "    \n",
    "    cash = float(initial_cash)\n",
    "    qty = 0.0\n",
    "    entry_px = np.nan\n",
    "    eq_rows = []\n",
    "    trades = []\n",
    "    idx = df_blk.index\n",
    "\n",
    "    for i in range(1, len(idx)-1):\n",
    "        t  = idx[i]      \n",
    "        t1 = idx[i+1]    \n",
    "\n",
    "        if qty != 0.0:\n",
    "            px_in = entry_px\n",
    "            high = df_blk.at[t1, \"high\"]\n",
    "            low  = df_blk.at[t1, \"low\"]\n",
    "            peak = max(px_in, high)\n",
    "            stop_lvl   = peak * (1 - tsl)\n",
    "            target_lvl = px_in * (1 + tp)\n",
    "\n",
    "            if low <= stop_lvl:\n",
    "                exit_px, reason = stop_lvl, \"TSL\"\n",
    "            elif high >= target_lvl:\n",
    "                exit_px, reason = target_lvl, \"TP\"\n",
    "            else:\n",
    "                exit_px, reason = df_blk.at[t1, \"open\"], \"Timeout\"\n",
    "\n",
    "            proceeds = qty * exit_px * (1 - fee_rate)\n",
    "            cash += proceeds\n",
    "            trades.append(dict(ts=t1, side=\"SELL\", qty=qty, price=exit_px,\n",
    "                               fee=qty*exit_px*fee_rate, reason=reason))\n",
    "            qty = 0.0\n",
    "            entry_px = np.nan\n",
    "\n",
    "        if bool(enter_flags.loc[t]) and qty == 0.0:\n",
    "            px_open  = df_blk.at[t, \"open\"]\n",
    "            notional = cash * spend_frac\n",
    "            if px_open > 0 and notional > 0:\n",
    "                qty = notional / (px_open * (1 + fee_rate))\n",
    "                cash -= qty * px_open * (1 + fee_rate)\n",
    "                entry_px = px_open\n",
    "                trades.append(dict(ts=t, side=\"BUY\", qty=qty, price=px_open,\n",
    "                                   fee=qty*px_open*fee_rate, reason=\"Enter\"))\n",
    "\n",
    "        eq_rows.append((t, cash + qty * df_blk.at[t, \"close\"]))\n",
    "\n",
    "    eq = pd.DataFrame(eq_rows, columns=[\"timestamp\",\"equity\"]).set_index(\"timestamp\")\n",
    "    tr = pd.DataFrame(trades)\n",
    "    return eq, tr, cash\n",
    "\n",
    "def buy_and_hold_global(df_full, fee_rate=FEE_RATE, initial_cash=INIT_CASH):\n",
    "    cash = float(initial_cash)\n",
    "    px_in = df_full.iloc[0][\"open\"]\n",
    "    qty = cash / (px_in * (1 + fee_rate))\n",
    "    cash -= qty * px_in * (1 + fee_rate)\n",
    "    equity = []\n",
    "    for i in range(len(df_full)):\n",
    "        t = df_full.index[i]\n",
    "        px = df_full.iloc[i][\"close\"]\n",
    "        equity.append((t, cash + qty * px))\n",
    "    return pd.DataFrame(equity, columns=[\"timestamp\",\"equity\"]).set_index(\"timestamp\")\n",
    "\n",
    "def buy_and_hold_over_windows(df_full, windows,\n",
    "                              fee_rate=FEE_RATE, initial_cash=INIT_CASH):\n",
    "    if not windows:\n",
    "        return pd.DataFrame(columns=[\"equity\"])\n",
    "\n",
    "    cash = float(initial_cash)\n",
    "    qty  = 0.0\n",
    "    eq_rows = []\n",
    "    first = True\n",
    "\n",
    "    for (test_start, test_end) in windows:\n",
    "        seg = df_full.loc[test_start:test_end]\n",
    "        if seg.empty:\n",
    "            continue\n",
    "        # Enter at first bar open of the FIRST segment\n",
    "        if first:\n",
    "            px_in = seg.iloc[0][\"open\"]\n",
    "            qty   = cash / (px_in * (1 + fee_rate))\n",
    "            cash -= qty * px_in * (1 + fee_rate)\n",
    "            first = False\n",
    "        # Mark to market across this segment\n",
    "        for i in range(len(seg)):\n",
    "            t  = seg.index[i]\n",
    "            px = seg.iloc[i][\"close\"]\n",
    "            eq_rows.append((t, cash + qty * px))\n",
    "\n",
    "    return pd.DataFrame(eq_rows, columns=[\"timestamp\",\"equity\"]).set_index(\"timestamp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(eq):\n",
    "    ret = eq[\"equity\"].pct_change().dropna()\n",
    "    if len(ret)==0 or ret.std()==0:\n",
    "        return pd.Series(dict(Sharpe=np.nan, Sortino=np.nan, MaxDD=np.nan,\n",
    "                              Calmar=np.nan, TotalRet=np.nan, VaR95=np.nan))\n",
    "    sharpe  = np.sqrt(H_PER_YR) * ret.mean() / ret.std()\n",
    "    downside= ret[ret<0]\n",
    "    sortino = np.sqrt(H_PER_YR) * ret.mean() / (downside.std() if downside.std() > 0 else np.nan)\n",
    "    curve   = eq[\"equity\"]\n",
    "    maxdd   = (curve/curve.cummax() - 1).min()\n",
    "    total   = curve.iloc[-1] / curve.iloc[0] - 1\n",
    "    var95   = np.percentile(ret, 5)\n",
    "    calmar  = (total + 1e-12) / abs(maxdd) if maxdd < 0 else np.nan\n",
    "    return pd.Series(dict(Sharpe=sharpe, Sortino=sortino, MaxDD=maxdd,\n",
    "                          Calmar=calmar, TotalRet=total, VaR95=var95))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_per_model(df_full, pred_col, mode,\n",
    "                           alphas=ALPHAS, q_window=Q_WINDOW,\n",
    "                           val_hours=VAL_H, test_hours=TEST_H, embargo_hours=EMBARGO_H,\n",
    "                           fee_rate=FEE_RATE, spend_frac=SPEND_FRAC, tp=TP_PCT, tsl=TSL_PCT,\n",
    "                           initial_cash=INIT_CASH):\n",
    "\n",
    "    idx = df_full.index\n",
    "    end = len(idx)\n",
    "\n",
    "    warmup = max(q_window + 2, 10)\n",
    "    i = warmup\n",
    "\n",
    "    eq_segments = []\n",
    "    trade_segments = []\n",
    "    chosen_rows = []\n",
    "    test_windows = []\n",
    "    cash_carry = float(initial_cash)\n",
    "\n",
    "    while True:\n",
    "        val_end = i + val_hours\n",
    "        test_start = val_end + embargo_hours\n",
    "        test_end = test_start + test_hours\n",
    "        if test_end >= end:\n",
    "            break\n",
    "\n",
    "        val_idx  = idx[i:val_end]\n",
    "        test_idx = idx[test_start:test_end]\n",
    "\n",
    "        best_alpha = None\n",
    "        best_sharpe = -np.inf\n",
    "        for a in alphas:\n",
    "            enter_val = build_enter_flags(df_full, pred_col, a, q_window, mode).reindex(val_idx)\n",
    "            eq_val, _, _ = backtest_block(df_full.loc[val_idx], enter_val,\n",
    "                                          fee_rate=fee_rate, spend_frac=spend_frac, tp=tp, tsl=tsl,\n",
    "                                          initial_cash=INIT_CASH)  \n",
    "            ret = eq_val[\"equity\"].pct_change().dropna()\n",
    "            sharpe = (np.sqrt(H_PER_YR) * ret.mean() / ret.std()) if ret.std() > 0 else -np.inf\n",
    "            if sharpe > best_sharpe:\n",
    "                best_sharpe = sharpe\n",
    "                best_alpha = a\n",
    "\n",
    "        chosen_rows.append(dict(\n",
    "            val_start=idx[i], val_end=idx[val_end-1],\n",
    "            test_start=idx[test_start], test_end=idx[test_end-1],\n",
    "            chosen_alpha=best_alpha, val_sharpe=best_sharpe\n",
    "        ))\n",
    "        test_windows.append((idx[test_start], idx[test_end-1]))\n",
    "\n",
    "        enter_test = build_enter_flags(df_full, pred_col, best_alpha, q_window, mode).reindex(test_idx)\n",
    "        eq_test, tr_test, cash_carry = backtest_block(\n",
    "            df_full.loc[test_idx], enter_test,\n",
    "            fee_rate=fee_rate, spend_frac=spend_frac, tp=tp, tsl=tsl,\n",
    "            initial_cash=cash_carry\n",
    "        )\n",
    "        eq_segments.append(eq_test)\n",
    "        tr_test[\"chosen_alpha\"] = best_alpha\n",
    "        trade_segments.append(tr_test)\n",
    "\n",
    "        i = test_end\n",
    "\n",
    "    equity_oos = pd.concat(eq_segments).sort_index() if eq_segments else pd.DataFrame(columns=[\"equity\"])\n",
    "    trades_oos = pd.concat(trade_segments, ignore_index=True) if trade_segments else pd.DataFrame()\n",
    "    chosen_log = pd.DataFrame(chosen_rows)\n",
    "    summary    = metrics(equity_oos).to_frame().T if not equity_oos.empty else pd.DataFrame()\n",
    "\n",
    "    return {\n",
    "        \"equity\": equity_oos,\n",
    "        \"trades\": trades_oos,\n",
    "        \"chosen_alpha_log\": chosen_log,\n",
    "        \"summary\": summary,\n",
    "        \"test_windows\": test_windows\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen alpha by block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Chosen α by block (per model × strategy) ===\n",
      " val_start  val_end  test_start  test_end  chosen_alpha  val_sharpe                  Model Strategy\n",
      "       170      889         891      1010          0.95   -0.394790 egarch_pred_vol_future  meanrev\n",
      "       170      889         891      1010          0.95   -5.668301 egarch_pred_vol_future momentum\n",
      "       170      889         891      1010          0.90   -1.769310   lstm_pred_vol_future  meanrev\n",
      "       170      889         891      1010          0.90   -3.154584   lstm_pred_vol_future momentum\n",
      "       170      889         891      1010          0.90   -9.288991    xgb_pred_vol_future  meanrev\n",
      "       170      889         891      1010          0.90  -10.752583    xgb_pred_vol_future momentum\n"
     ]
    }
   ],
   "source": [
    "alpha_rows = []\n",
    "for tag, log in all_choices.items():\n",
    "    if log is None or log.empty:\n",
    "        continue\n",
    "    # tag looks like \"xgb_pred_vol_future__momentum\"\n",
    "    parts = tag.split(\"__\")\n",
    "    model = parts[0]\n",
    "    strategy = parts[1] if len(parts) > 1 else \"NA\"\n",
    "\n",
    "    tmp = log[[\"val_start\",\"val_end\",\"test_start\",\"test_end\",\"chosen_alpha\",\"val_sharpe\"]].copy()\n",
    "    tmp[\"Model\"] = model\n",
    "    tmp[\"Strategy\"] = strategy\n",
    "    alpha_rows.append(tmp)\n",
    "\n",
    "alpha_table = (pd.concat(alpha_rows, ignore_index=True)\n",
    "                 .sort_values([\"test_start\",\"Model\",\"Strategy\"])\n",
    "                 .reset_index(drop=True))\n",
    "\n",
    "print(\"\\n=== Chosen α by block (per model × strategy) ===\")\n",
    "print(alpha_table.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trades done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Trades per test block ===\n",
      "                 Model Strategy  test_start  test_end  trades_in_block  chosen_alpha\n",
      "egarch_pred_vol_future  meanrev       891.0    1010.0                2          0.95\n",
      "egarch_pred_vol_future momentum       891.0    1010.0               12          0.95\n",
      "  lstm_pred_vol_future  meanrev       891.0    1010.0               12          0.90\n",
      "  lstm_pred_vol_future momentum       891.0    1010.0               30          0.90\n",
      "   xgb_pred_vol_future  meanrev       891.0    1010.0               62          0.90\n",
      "   xgb_pred_vol_future momentum       891.0    1010.0               96          0.90\n"
     ]
    }
   ],
   "source": [
    "trade_rows = []\n",
    "for tag, tr in all_trades.items():\n",
    "    if tr is None or tr.empty:\n",
    "        continue\n",
    "    model, strategy = tag.split(\"__\")\n",
    "\n",
    "    log = all_choices[tag]\n",
    "    for _, r in log.iterrows():\n",
    "        mask = (tr[\"ts\"] >= r[\"test_start\"]) & (tr[\"ts\"] <= r[\"test_end\"])\n",
    "        trade_rows.append({\n",
    "            \"Model\": model,\n",
    "            \"Strategy\": strategy,\n",
    "            \"test_start\": r[\"test_start\"],\n",
    "            \"test_end\": r[\"test_end\"],\n",
    "            \"trades_in_block\": int(mask.sum()),\n",
    "            \"chosen_alpha\": r[\"chosen_alpha\"]\n",
    "        })\n",
    "\n",
    "trades_per_block = (pd.DataFrame(trade_rows)\n",
    "                      .sort_values([\"test_start\",\"Model\",\"Strategy\"])\n",
    "                      .reset_index(drop=True))\n",
    "\n",
    "print(\"\\n=== Trades per test block ===\")\n",
    "print(trades_per_block.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumamry of Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model            Strategy   Sharpe  Sortino   MaxDD  \\\n",
      "0    lstm_pred_vol_future            momentum  -1.9407  -0.8650 -0.0008   \n",
      "1    lstm_pred_vol_future             meanrev   9.3969  10.5423 -0.0002   \n",
      "2  egarch_pred_vol_future            momentum   8.6322   4.5651 -0.0002   \n",
      "3  egarch_pred_vol_future             meanrev   2.4460      NaN -0.0000   \n",
      "4     xgb_pred_vol_future            momentum  -1.9628  -1.9272 -0.0012   \n",
      "5     xgb_pred_vol_future             meanrev   7.2182   9.3185 -0.0015   \n",
      "6         Buy&Hold_Global                Hold   0.2113   0.2519 -0.1278   \n",
      "7       Buy&Hold_Stitched  Hold(test-windows)  16.4235  29.8634 -0.0147   \n",
      "\n",
      "   Calmar  TotalRet   VaR95  \n",
      "0 -0.3302   -0.0003 -0.0001  \n",
      "1  2.8807    0.0006  0.0000  \n",
      "2  2.5803    0.0006  0.0000  \n",
      "3  0.5152    0.0000  0.0000  \n",
      "4 -0.3645   -0.0004 -0.0003  \n",
      "5  0.9746    0.0015 -0.0001  \n",
      "6  0.0166    0.0021 -0.0049  \n",
      "7  4.3584    0.0643 -0.0027  \n"
     ]
    }
   ],
   "source": [
    "pred_cols_present = [c for c in pred_cols if c in master.columns]\n",
    "modes = [\"momentum\", \"meanrev\"]\n",
    "\n",
    "all_summaries = []\n",
    "all_equities  = {}\n",
    "all_trades    = {}\n",
    "all_choices   = {}\n",
    "\n",
    "# Global Buy & Hold (full period)\n",
    "bh_global = buy_and_hold_global(master)\n",
    "\n",
    "for m in pred_cols_present:\n",
    "    for mode in modes:\n",
    "        res = walk_forward_per_model(\n",
    "            master, pred_col=m, mode=mode,\n",
    "            alphas=ALPHAS, q_window=Q_WINDOW,\n",
    "            val_hours=VAL_H, test_hours=TEST_H, embargo_hours=EMBARGO_H,\n",
    "            fee_rate=FEE_RATE, spend_frac=SPEND_FRAC, tp=TP_PCT, tsl=TSL_PCT,\n",
    "            initial_cash=INIT_CASH\n",
    "        )\n",
    "        tag = m + \"__\" + mode\n",
    "        all_equities[tag] = res[\"equity\"]\n",
    "        all_trades[tag]   = res[\"trades\"]\n",
    "        all_choices[tag]  = res[\"chosen_alpha_log\"]\n",
    "        s = res[\"summary\"].copy()\n",
    "        s.insert(0, \"Model\", m)\n",
    "        s.insert(1, \"Strategy\", mode)\n",
    "        all_summaries.append(s)\n",
    "\n",
    "# Build a stitched Buy&Hold over the SAME test windows (union of all)\n",
    "all_windows = []\n",
    "for v in all_choices.values():\n",
    "    if not v.empty:\n",
    "        for _, r in v.iterrows():\n",
    "            all_windows.append((r[\"test_start\"], r[\"test_end\"]))\n",
    "all_windows = sorted(list(set(all_windows)))\n",
    "bh_stitched = buy_and_hold_over_windows(master, all_windows)\n",
    "\n",
    "# Collect summaries\n",
    "summary_table = pd.concat(all_summaries, ignore_index=True) if all_summaries else pd.DataFrame()\n",
    "if not bh_global.empty:\n",
    "    s_bh_global = metrics(bh_global).to_frame().T\n",
    "    s_bh_global.insert(0, \"Model\", \"Buy&Hold_Global\")\n",
    "    s_bh_global.insert(1, \"Strategy\", \"Hold\")\n",
    "    summary_table = pd.concat([summary_table, s_bh_global], ignore_index=True)\n",
    "\n",
    "if not bh_stitched.empty:\n",
    "    s_bh_stitch = metrics(bh_stitched).to_frame().T\n",
    "    s_bh_stitch.insert(0, \"Model\", \"Buy&Hold_Stitched\")\n",
    "    s_bh_stitch.insert(1, \"Strategy\", \"Hold(test-windows)\")\n",
    "    summary_table = pd.concat([summary_table, s_bh_stitch], ignore_index=True)\n",
    "\n",
    "print(summary_table.round(4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EGARCH (Local)",
   "language": "python",
   "name": "egarch_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
