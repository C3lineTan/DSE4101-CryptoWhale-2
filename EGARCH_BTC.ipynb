{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating baseline model EGARCH for BTC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from arch.univariate import EGARCH, ZeroMean, StudentsT, Normal\n",
    "from statsmodels.tools.sm_exceptions import InterpolationWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to import this for rmse and qlike\n",
    "#import numpy as np\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "\n",
    "\n",
    "def qlike(y2, var_fc, eps=1e-12):\n",
    "    ratio = (y2 + eps) / (var_fc + eps)\n",
    "    return float(np.mean(ratio - np.log(ratio) - 1.0))\n",
    "\n",
    "\n",
    "def clean_series(x, name=\"series\"):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").astype(float)\n",
    "    x = x.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if not x.index.is_monotonic_increasing:\n",
    "        x = x.sort_index()\n",
    "    return x\n",
    "\n",
    "\n",
    "def scale_series(x, factor=100.0):\n",
    "    if factor is None or factor == 1.0:\n",
    "        return x, 1.0\n",
    "    return x * factor, factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index dtype: datetime64[ns, UTC]\n",
      "Columns: Index(['btc_exchange_netflow_usd', 'active_sending_addresses',\n",
      "       'active_receiving_addresses', 'onchain_volume_usd', 'open', 'low',\n",
      "       'high', 'close', 'mint_reward_usd', 'total_fee_usd',\n",
      "       'transaction_count', 'wallet_to_exchange_usd', 'realized_volatility',\n",
      "       'RV_MA_1hr', 'RV_MA_3hr', 'RV_MA_12hr', 'hourly_return'],\n",
      "      dtype='object')\n",
      "Data shape: (8208, 17)\n",
      "\n",
      "Using 8208 observations for EGARCH modelling.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dune_btc_hour.csv\")\n",
    "df['hour_utc'] = pd.to_datetime(df['hour_utc'], utc=True)\n",
    "\n",
    "\n",
    "df = df.set_index('hour_utc')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df = df.sort_index()\n",
    "df = df[~df.index.duplicated(keep='last')]\n",
    "\n",
    "df['hourly_return'] = clean_series(df['hourly_return'], name=\"hourly_return_all\")\n",
    "r = df['hourly_return']\n",
    "\n",
    "print(\"Index dtype:\", df.index.dtype)\n",
    "print(\"Columns:\", df.columns)\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(f\"\\nUsing {len(r)} observations for EGARCH modelling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining stationary tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stationarity Tests ===\n",
      "{'ADF': {'stat': np.float64(-20.879240730752954), 'p': 0.0}, 'KPSS_level': {'stat': np.float64(0.1442031290166316), 'p': np.float64(0.1)}, 'KPSS_trend': {'stat': np.float64(0.10581848073629616), 'p': np.float64(0.1)}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/bmfws9h55z1g8ckt55h4p8jr0000gn/T/ipykernel_4334/463190570.py:4: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  kpss_level = kpss(x, regression=\"c\", nlags=\"auto\")\n",
      "/var/folders/ql/bmfws9h55z1g8ckt55h4p8jr0000gn/T/ipykernel_4334/463190570.py:5: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  kpss_trend = kpss(x, regression=\"ct\", nlags=\"auto\")\n"
     ]
    }
   ],
   "source": [
    "def adf_kpss(x: pd.Series):\n",
    "    x = x.dropna()\n",
    "    adf_res = adfuller(x, autolag=\"AIC\")\n",
    "    kpss_level = kpss(x, regression=\"c\", nlags=\"auto\")\n",
    "    kpss_trend = kpss(x, regression=\"ct\", nlags=\"auto\")\n",
    "    return {\n",
    "        \"ADF\": {\"stat\": adf_res[0], \"p\": adf_res[1]},\n",
    "        \"KPSS_level\": {\"stat\": kpss_level[0], \"p\": kpss_level[1]},\n",
    "        \"KPSS_trend\": {\"stat\": kpss_trend[0], \"p\": kpss_trend[1]},\n",
    "    }\n",
    "\n",
    "print(\"\\n=== Stationarity Tests ===\")\n",
    "print(adf_kpss(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use table to show at least weak stationarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Statistic</th>\n",
       "      <th>p-value</th>\n",
       "      <th>H0</th>\n",
       "      <th>Decision @ 5%</th>\n",
       "      <th>Lags used</th>\n",
       "      <th>Obs used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADF</td>\n",
       "      <td>-20.879241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unit root (non-stationary)</td>\n",
       "      <td>Stationary (reject H0)</td>\n",
       "      <td>22</td>\n",
       "      <td>8184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KPSS (level)</td>\n",
       "      <td>0.144203</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Level-stationary</td>\n",
       "      <td>Stationary (fail to reject)</td>\n",
       "      <td>6</td>\n",
       "      <td>8207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KPSS (trend)</td>\n",
       "      <td>0.105818</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Trend-stationary</td>\n",
       "      <td>Stationary (fail to reject)</td>\n",
       "      <td>7</td>\n",
       "      <td>8207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Test  Statistic  p-value                          H0  \\\n",
       "0           ADF -20.879241      0.0  Unit root (non-stationary)   \n",
       "1  KPSS (level)   0.144203      0.1            Level-stationary   \n",
       "2  KPSS (trend)   0.105818      0.1            Trend-stationary   \n",
       "\n",
       "                 Decision @ 5%  Lags used  Obs used  \n",
       "0       Stationary (reject H0)         22      8184  \n",
       "1  Stationary (fail to reject)          6      8207  \n",
       "2  Stationary (fail to reject)          7      8207  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stationarity_table(x, alpha=0.05):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").astype(float).dropna()\n",
    "\n",
    "    adf_stat, adf_p, adf_lags, adf_nobs, adf_crit, *_ = adfuller(x, autolag=\"AIC\")\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=InterpolationWarning)\n",
    "        kpss_level_stat, kpss_level_p, kpss_level_lags, kpss_level_crit = kpss(x, regression=\"c\", nlags=\"auto\")\n",
    "        kpss_trend_stat, kpss_trend_p, kpss_trend_lags, kpss_trend_crit = kpss(x, regression=\"ct\", nlags=\"auto\")\n",
    "\n",
    "    rows = [\n",
    "        {\n",
    "            \"Test\": \"ADF\",\n",
    "            \"Statistic\": adf_stat,\n",
    "            \"p-value\": adf_p,\n",
    "            \"H0\": \"Unit root (non-stationary)\",\n",
    "            f\"Decision @ {int(alpha*100)}%\": \"Stationary (reject H0)\" if adf_p < alpha else \"Non-stationary (fail to reject)\",\n",
    "            \"Lags used\": adf_lags,\n",
    "            \"Obs used\": adf_nobs,\n",
    "        },\n",
    "        {\n",
    "            \"Test\": \"KPSS (level)\",\n",
    "            \"Statistic\": kpss_level_stat,\n",
    "            \"p-value\": kpss_level_p,\n",
    "            \"H0\": \"Level-stationary\",\n",
    "            f\"Decision @ {int(alpha*100)}%\": \"Non-stationary (reject H0)\" if kpss_level_p < alpha else \"Stationary (fail to reject)\",\n",
    "            \"Lags used\": kpss_level_lags,\n",
    "            \"Obs used\": len(x),\n",
    "        },\n",
    "        {\n",
    "            \"Test\": \"KPSS (trend)\",\n",
    "            \"Statistic\": kpss_trend_stat,\n",
    "            \"p-value\": kpss_trend_p,\n",
    "            \"H0\": \"Trend-stationary\",\n",
    "            f\"Decision @ {int(alpha*100)}%\": \"Non-stationary (reject H0)\" if kpss_trend_p < alpha else \"Stationary (fail to reject)\",\n",
    "            \"Lags used\": kpss_trend_lags,\n",
    "            \"Obs used\": len(x),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    return df_out\n",
    "\n",
    "    num_cols = [\"Statistic\", \"p-value\"]\n",
    "    df_out[num_cols] = df_out[num_cols].applymap(lambda v: np.nan if pd.isna(v) else float(v))\n",
    "    return df_out\n",
    "\n",
    "tbl = stationarity_table(r, alpha=0.05)\n",
    "tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation/Test Split (70/15/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val for CV: 6988 obs  |  Test (after 12h purge): 1220 obs\n"
     ]
    }
   ],
   "source": [
    "use_validation = True \n",
    "n = len(r)\n",
    "if use_validation:\n",
    "    n_train = int(0.70 * n)\n",
    "    n_val   = int(0.15 * n)\n",
    "    train_proto = r.iloc[:n_train]\n",
    "    val_proto   = r.iloc[n_train:n_train+n_val]\n",
    "    test_proto  = r.iloc[n_train+n_val:]\n",
    "else:\n",
    "    n_train = int(0.85 * n)\n",
    "    train_proto = r.iloc[:n_train]\n",
    "    val_proto   = None\n",
    "    test_proto  = r.iloc[n_train:]\n",
    "\n",
    "PURGE_HOURS = 12\n",
    "if len(test_proto) == 0:\n",
    "    raise ValueError(\"Empty test set after temporal split.\")\n",
    "boundary = test_proto.index.min()\n",
    "purged_start = boundary + pd.Timedelta(hours=PURGE_HOURS)\n",
    "\n",
    "train_val = r.loc[: purged_start - pd.Timedelta(hours=1)]\n",
    "test      = r.loc[purged_start:]\n",
    "\n",
    "print(f\"Train/Val for CV: {len(train_val)} obs  |  Test (after 12h purge): {len(test)} obs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling Window = 5 Splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_split(x, n_splits=5, min_train_size=100):\n",
    "    n = len(x)\n",
    "    sizes = np.full(n_splits, n // n_splits, dtype=int)\n",
    "    sizes[: n % n_splits] += 1\n",
    "\n",
    "    idx = np.arange(n)\n",
    "    cur = 0\n",
    "    for fs in sizes:\n",
    "        test_start, test_end = cur, cur + fs\n",
    "        cur = test_end\n",
    "        if test_start < min_train_size:\n",
    "            continue\n",
    "        yield idx[:test_start], idx[test_start:test_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit EGARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def egarch_path_refit(train_ret, test_ret, dist=\"t\", scale=100.0):\n",
    "    tr = clean_series(train_ret, \"train_ret\")\n",
    "    te = clean_series(test_ret, \"test_ret\")\n",
    "\n",
    "    tr_s, s = scale_series(tr, scale)\n",
    "    te_s, _ = scale_series(te, scale)\n",
    "\n",
    "    all_s = pd.concat([tr_s, te_s])\n",
    "    n_tr, n_te = len(tr_s), len(te_s)\n",
    "\n",
    "    var_fc_s = np.empty(n_te)\n",
    "\n",
    "    for j in range(n_te):\n",
    "        y_fit = all_s.iloc[: n_tr + j]\n",
    "        model = ZeroMean(y_fit)\n",
    "        model.volatility = EGARCH(p=1, o=1, q=1)\n",
    "        model.distribution = StudentsT() if dist == \"t\" else Normal()\n",
    "        res = model.fit(disp=\"off\")\n",
    "\n",
    "        fcast = res.forecast(horizon=1, reindex=False)\n",
    "        var_fc_s[j] = float(fcast.variance.values[-1, 0])\n",
    "\n",
    "    var_fc = var_fc_s / (s ** 2)\n",
    "    r2 = te.values ** 2\n",
    "\n",
    "    return {\n",
    "        \"var_fc\": var_fc,\n",
    "        \"r2\": r2,\n",
    "        \"rmse\": rmse(r2, var_fc),\n",
    "        \"qlike\": qlike(r2, var_fc),\n",
    "        \"n_train\": len(tr),\n",
    "        \"n_test\": len(te),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rolling CV (5 splits)===\n",
      "Fold 1: RMSE=9.505968e-05 | QLIKE=1.729956 | Train=1397 Test=1398\n",
      "Fold 2: RMSE=1.396738e-04 | QLIKE=1.696587 | Train=2795 Test=1398\n",
      "Fold 3: RMSE=3.904055e-05 | QLIKE=1.731113 | Train=4193 Test=1397\n",
      "Fold 4: RMSE=3.410794e-05 | QLIKE=1.741678 | Train=5590 Test=1397\n",
      "\n",
      "Mean CV RMSE=7.697049e-05 | Mean CV QLIKE=1.724833\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Rolling CV (5 splits)===\")\n",
    "cv_scores = []\n",
    "for i, (tri, tei) in enumerate(rolling_split(train_val, n_splits=5, min_train_size=100), 1):\n",
    "    tr_i = train_val.iloc[tri]\n",
    "    te_i = train_val.iloc[tei]\n",
    "    \n",
    "    out = egarch_path_refit(tr_i, te_i, dist=\"t\", scale=100.0)\n",
    "    cv_scores.append((out[\"rmse\"], out[\"qlike\"]))\n",
    "    print(f\"Fold {i}: RMSE={out['rmse']:.6e} | QLIKE={out['qlike']:.6f} \"\n",
    "            f\"| Train={out['n_train']} Test={out['n_test']}\")\n",
    "    \n",
    "\n",
    "if cv_scores:\n",
    "    mean_rmse  = float(np.mean([s[0] for s in cv_scores]))\n",
    "    mean_qlike = float(np.mean([s[1] for s in cv_scores]))\n",
    "    print(f\"\\nMean CV RMSE={mean_rmse:.6e} | Mean CV QLIKE={mean_qlike:.6f}\")\n",
    "else:\n",
    "    print(\"No valid CV folds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Test Results ===\n",
      "Test RMSE=4.695800e-05 | QLIKE=1.849920\n"
     ]
    }
   ],
   "source": [
    "final_train = train_val \n",
    "final_out = egarch_path_refit(final_train, test, dist=\"t\", scale=100.0)\n",
    "print(\"\\n=== Final Test Results ===\")\n",
    "print(f\"Test RMSE={final_out['rmse']:.6e} | QLIKE={final_out['qlike']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on why RMSE is so low - due to scaling since returns are of small magnitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale checks:\n",
      "mean|r|     = 3.077e-03\n",
      "mean r^2    = 2.272e-05\n",
      "std(r)^2    = 2.271e-05\n",
      "\n",
      "Metrics (scientific):\n",
      "RMSE       = 4.696e-05\n",
      "QLIKE      = 1.849920\n",
      "\n",
      "Forecast variance summary:\n",
      "min=2.330e-06  p50=1.096e-05  mean=1.570e-05  max=2.477e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"Scale checks:\")\n",
    "print(f\"mean|r|     = {np.mean(np.abs(r)):.3e}\")\n",
    "print(f\"mean r^2    = {np.mean(r**2):.3e}\")\n",
    "print(f\"std(r)^2    = {np.std(r)**2:.3e}\")  \n",
    "\n",
    "\n",
    "print(\"\\nMetrics (scientific):\")\n",
    "print(f\"RMSE       = {final_out['rmse']:.3e}\")   \n",
    "print(f\"QLIKE      = {final_out['qlike']:.6f}\")\n",
    "\n",
    "\n",
    "vf = final_out['var_fc']\n",
    "print(\"\\nForecast variance summary:\")\n",
    "print(f\"min={vf.min():.3e}  p50={np.median(vf):.3e}  mean={vf.mean():.3e}  max={vf.max():.3e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EGARCH (Local)",
   "language": "python",
   "name": "egarch_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
